{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e07680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#SK Learn\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "#Stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "#My imports\n",
    "import wrangle as w\n",
    "import env\n",
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e49c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = w.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb37b4f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>fips</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>parcelid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>33634931.0</td>\n",
       "      <td>-117869207.0</td>\n",
       "      <td>4506.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1023282.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>14297519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>34449266.0</td>\n",
       "      <td>-119281531.0</td>\n",
       "      <td>12647.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>464000.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>17052889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedroomcnt  bathroomcnt  calculatedfinishedsquarefeet    fips    latitude  \\\n",
       "0         4.0          3.5                        3100.0  6059.0  33634931.0   \n",
       "1         2.0          1.0                        1465.0  6111.0  34449266.0   \n",
       "\n",
       "     longitude  lotsizesquarefeet  yearbuilt  taxvaluedollarcnt  \\\n",
       "0 -117869207.0             4506.0     1998.0          1023282.0   \n",
       "1 -119281531.0            12647.0     1967.0           464000.0   \n",
       "\n",
       "  transactiondate  parcelid  \n",
       "0      2017-01-01  14297519  \n",
       "1      2017-01-01  17052889  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6491375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52442 entries, 0 to 52441\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   bedroomcnt                    52442 non-null  float64\n",
      " 1   bathroomcnt                   52442 non-null  float64\n",
      " 2   calculatedfinishedsquarefeet  52360 non-null  float64\n",
      " 3   fips                          52442 non-null  float64\n",
      " 4   latitude                      52442 non-null  float64\n",
      " 5   longitude                     52442 non-null  float64\n",
      " 6   lotsizesquarefeet             52073 non-null  float64\n",
      " 7   yearbuilt                     52326 non-null  float64\n",
      " 8   taxvaluedollarcnt             52441 non-null  float64\n",
      " 9   transactiondate               52442 non-null  object \n",
      " 10  parcelid                      52442 non-null  int64  \n",
      "dtypes: float64(9), int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a13bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the data, removing nulls, duplicates, and outliers\n",
    "df = w.clean_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4ce015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>fips</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>year_built</th>\n",
       "      <th>tax_value</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>parcel_id</th>\n",
       "      <th>LA</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Ventura</th>\n",
       "      <th>home_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>6059</td>\n",
       "      <td>33634931.0</td>\n",
       "      <td>-117869207.0</td>\n",
       "      <td>4506</td>\n",
       "      <td>1998</td>\n",
       "      <td>1023282</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>14297519</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>6111</td>\n",
       "      <td>34449266.0</td>\n",
       "      <td>-119281531.0</td>\n",
       "      <td>12647</td>\n",
       "      <td>1967</td>\n",
       "      <td>464000</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>17052889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  square_feet  fips    latitude    longitude  lot_size  \\\n",
       "0         4        3.5       3100.0  6059  33634931.0 -117869207.0      4506   \n",
       "1         2        1.0       1465.0  6111  34449266.0 -119281531.0     12647   \n",
       "\n",
       "   year_built  tax_value transaction_date  parcel_id  LA  Orange  Ventura  \\\n",
       "0        1998    1023282       2017-01-01   14297519   0       1        0   \n",
       "1        1967     464000       2017-01-01   17052889   0       0        1   \n",
       "\n",
       "   home_age  \n",
       "0        19  \n",
       "1        50  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd14a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting our data\n",
    "train, validate, test = w.train_validate_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b6922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train length is 32903 rows\n",
      " Validate length is 7053 rows\n",
      " Test length is 7052 rows\n"
     ]
    }
   ],
   "source": [
    "print(f' Train length is {len(train)} rows')\n",
    "print(f' Validate length is {len(validate)} rows')\n",
    "print(f' Test length is {len(test)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ec9f0",
   "metadata": {},
   "source": [
    "## Categorical Variable Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ab0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af85c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breaking down continuous vs categorical variables\n",
    "cat_vars = ['bedrooms', 'LA', 'Orange', 'Ventura']\n",
    "cont_vars = ['bathrooms', 'square_feet', 'lot_size', 'tax_value', 'home_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_and_continuous_vars(df, cat_vars, cont_vars):\n",
    "    for col in cat_vars:\n",
    "        for col2 in cont_vars:\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(16,6))\n",
    "            fig.suptitle(f'{col} vs. {col2}')\n",
    "            sns.boxplot(data=df, x=col, y=col2, ax=ax1)\n",
    "            sns.violinplot(data=df, x=col, y=col2, ax=ax2)\n",
    "            sns.barplot(data=df, x=col, y=col2, ax=ax3)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_and_continuous_vars(train, cat_vars, cont_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81219352",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "cols = ['bedrooms', 'bathrooms', 'home_age']\n",
    "for i, col in enumerate(cols):\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    subplot_num = i+1\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,4,subplot_num)\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "    # Display histogram for column.\n",
    "    train[col].hist(bins=10)\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_vars:\n",
    "    print(col)\n",
    "    print(train[col].value_counts())\n",
    "    print(train[col].value_counts(normalize=True)*100)\n",
    "    sns.countplot(x=col, data=train)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f4bdd",
   "metadata": {},
   "source": [
    "### Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e30b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7), tight_layout = True)\n",
    "ax.hist(train.bedrooms)\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"y-axis\")\n",
    "plt.title('Bedrooms Histogram')\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c816fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displot\n",
    "sns.displot(x='bedrooms', data=train, bins=5)\n",
    "plt.title('bedrooms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa273cb2",
   "metadata": {},
   "source": [
    "### Continuous Variable Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize other numeric data\n",
    "# Plot numeric columns\n",
    "for col in cont_vars:\n",
    "    print(f'Mean {col} is: {train[col].mean()}')\n",
    "    plt.hist(train[col])\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "    plt.boxplot(train[col])\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "    sns.displot(train[col])\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics\n",
    "print(f'Mean bedrooms = {train.bedrooms.mean()}')\n",
    "print(f'Median Bedrooms = {train.bedrooms.median()}')\n",
    "print(f'Mode Bedrooms = {train.bedrooms.mode()}')\n",
    "print(f'Max Bedrooms = {train.bedrooms.max()}')\n",
    "print(f'Min Bedrooms = {train.bedrooms.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bathrooms in train data set\n",
    "train.bathrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics of bathrooms\n",
    "print(f'Mean Bathrooms = {train.bathrooms.mean()}')\n",
    "print(f'Median Bathrooms = {train.bathrooms.median()}')\n",
    "print(f'Mode Bathrooms = {train.bathrooms.mode()}')\n",
    "print(f'Max Bathrooms = {train.bathrooms.max()}')\n",
    "print(f'Min Bathrooms = {train.bathrooms.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38985c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7), tight_layout = True)\n",
    "ax.hist(train.bathrooms, bins = [0, 1,2,3,4,5])\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"y-axis\")\n",
    "plt.title('Bathrooms Histogram')\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24775c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displot\n",
    "sns.displot(x='bathrooms', data=train, bins=5)\n",
    "plt.title('bathrooms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9657149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Square Feet versus tax Value\n",
    "sns.relplot(train['square_feet'], train['tax_value'], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f21b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Square Feet versus tax Value\n",
    "sns.lmplot(x='square_feet', y='tax_value', data=train, scatter=True, line_kws={'color': 'red'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca3c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bathrooms versus tax Value\n",
    "sns.relplot(train['home_age'], train['tax_value'], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x, y, data=train, kind=scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d468297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf31d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ef5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fe538e9",
   "metadata": {},
   "source": [
    "# Modeling Iteration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f64937e",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd8a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data for modeling\n",
    "train, validate, test = m.scale_data(\n",
    "    train, validate, test, columns_to_scale=[\n",
    "        'bedrooms', 'bathrooms', 'square_feet','lot_size','home_age'],return_scaler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4765892c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>fips</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>year_built</th>\n",
       "      <th>tax_value</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>parcel_id</th>\n",
       "      <th>LA</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Ventura</th>\n",
       "      <th>home_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51187</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.231577</td>\n",
       "      <td>6037</td>\n",
       "      <td>34117365.0</td>\n",
       "      <td>-117839192.0</td>\n",
       "      <td>0.394667</td>\n",
       "      <td>1958</td>\n",
       "      <td>137233</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>13035327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.390737</td>\n",
       "      <td>6111</td>\n",
       "      <td>34292708.0</td>\n",
       "      <td>-118681581.0</td>\n",
       "      <td>0.228501</td>\n",
       "      <td>2000</td>\n",
       "      <td>701000</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>17240834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  square_feet  fips    latitude    longitude  \\\n",
       "51187       0.6   0.363636     0.231577  6037  34117365.0 -117839192.0   \n",
       "3300        0.4   0.454545     0.390737  6111  34292708.0 -118681581.0   \n",
       "\n",
       "       lot_size  year_built  tax_value transaction_date  parcel_id  LA  \\\n",
       "51187  0.394667        1958     137233       2017-09-12   13035327   1   \n",
       "3300   0.228501        2000     701000       2017-01-24   17240834   0   \n",
       "\n",
       "       Orange  Ventura  home_age  \n",
       "51187       0        0  0.416058  \n",
       "3300        0        1  0.109489  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a81a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep data for modeling iteration 1\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = m.model1_prep(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95263277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Baseline using median\n",
    "baseline = train.tax_value.median()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5af53",
   "metadata": {},
   "source": [
    "### Evaluating Residuals with chosen method of polynomial features/linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model, choosing polynomial regression\n",
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree3 = pf.transform(X_validate)\n",
    "X_test_degree3 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11618100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "plr = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "plr.fit(X_train_degree3, y_train.tax_value)\n",
    "\n",
    "# predict train\n",
    "y_train['tax_value_pred_plr'] = plr.predict(X_train_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_plr)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['tax_value_pred_plr'] = plr.predict(X_validate_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_plr)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=3\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ec1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1611cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating basemodel to evaluate residuals\n",
    "basemodel = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['bedrooms', 'bathrooms', 'square_feet', 'tax_value']\n",
    "basemodel = basemodel[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594d8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f86e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = y_train.tax_value_pred_plr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.tax_value_pred_plr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a328f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute residuals\n",
    "basemodel['yhat_baseline'] = df['tax_value'].median()\n",
    "basemodel.head(3)\n",
    "\n",
    "basemodel['residual'] = y_train['tax_value_pred_plr'] - basemodel['tax_value']\n",
    "\n",
    "basemodel['residual_baseline'] = basemodel['yhat_baseline'] - basemodel['tax_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a688ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel['yhat'] = y_train['tax_value_pred_plr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c753f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8093799",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.loc[[22349]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.loc[[22349]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.loc[[22349]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d09659",
   "metadata": {},
   "source": [
    "### Examining RFE to select features to move to modeling iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0be59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b839b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dummy variables from county\n",
    "#train = pd.get_dummies(train, columns=['county'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.rename(columns = {'county_Los Angeles':'LA', 'county_Orange':'Orange','county_Ventura':'Ventura'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc882e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not needed for modeling\n",
    "train = train.drop(['fips', 'latitude', 'longitude', 'year_built', 'transaction_date', 'parcel_id'], axis=1)\n",
    "validate = validate.drop(['fips', 'latitude', 'longitude', 'year_built', 'transaction_date', 'parcel_id'], axis=1)\n",
    "test = test.drop(['fips', 'latitude', 'longitude', 'year_built', 'transaction_date', 'parcel_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cf32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74edbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale our data for modeling\n",
    "train, validate, test = m.scale_data(\n",
    "    train,validate,test,columns_to_scale=['bedrooms','bathrooms','square_feet','lot_size','home_age'],\n",
    "    return_scaler=False\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57843675",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a242865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into predicting variables (X) and target variable (y) and reset the index for each dataframe\n",
    "X_train = train.drop(columns='tax_value').reset_index(drop=True)\n",
    "y_train = train[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "X_validate = validate.drop(columns='tax_value').reset_index(drop=True)\n",
    "y_validate = validate[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "X_test = test.drop(columns='tax_value').reset_index(drop=True)\n",
    "y_test = test[['tax_value']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21653dc",
   "metadata": {},
   "source": [
    "### Trying RFE first with linear regression (either normalize = True or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970632fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ML algorithm\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "# create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "rfe = RFE(lm, n_features_to_select=3)\n",
    "\n",
    "# fit the data using RFE\n",
    "rfe.fit(X_train, y_train)  \n",
    "\n",
    "# get the mask of the columns selected\n",
    "feature_mask = rfe.support_\n",
    "\n",
    "# get list of the column names. \n",
    "rfe_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "rfe_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba64611",
   "metadata": {},
   "source": [
    "#### Changing n features to select from 3-5 gives different results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c4fa3",
   "metadata": {},
   "source": [
    "### RFE with lasso lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ML algorithm\n",
    "lars = LassoLars(alpha=1.0)\n",
    "\n",
    "# create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "rfe = RFE(lars, n_features_to_select=3)\n",
    "\n",
    "# fit the data using RFE\n",
    "rfe.fit(X_train, y_train)  \n",
    "\n",
    "# get the mask of the columns selected\n",
    "feature_mask = rfe.support_\n",
    "\n",
    "# get list of the column names. \n",
    "rfe_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "rfe_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "lars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0520927",
   "metadata": {},
   "source": [
    "#### Lasso Lars seems to be more consistent, giving bedrooms, bathrooms, square feet, and then adding on as you increase n features to select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78422972",
   "metadata": {},
   "source": [
    "### RFE Tweedie Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=0, alpha=1.0)\n",
    "# create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "rfe = RFE(glm, n_features_to_select=3)\n",
    "\n",
    "# fit the data using RFE\n",
    "rfe.fit(X_train, y_train)  \n",
    "\n",
    "# get the mask of the columns selected\n",
    "feature_mask = rfe.support_\n",
    "\n",
    "# get list of the column names. \n",
    "rfe_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "rfe_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfea0d8",
   "metadata": {},
   "source": [
    "#### Not sure if Tweedie will end up being a good fit for final model, but bathrooms, square feet, and county LA seem to be the most driving. Lot Size and bedrooms become important as you add to n features to select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b99a6",
   "metadata": {},
   "source": [
    "### RFE Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model object\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "pf.fit_transform(X_train)\n",
    "\n",
    "# create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "rfe = RFE(pf, n_features_to_select=3)\n",
    "\n",
    "# fit the data using RFE\n",
    "rfe.fit(X_train, y_train)  \n",
    "\n",
    "# get the mask of the columns selected\n",
    "feature_mask = rfe.support_\n",
    "\n",
    "# get list of the column names. \n",
    "rfe_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "rfe_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53897b89",
   "metadata": {},
   "source": [
    "### Evaluate Using Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# parameters: f_regression stats test, give me 4 features\n",
    "f_selector = SelectKBest(f_regression, k=4)\n",
    "\n",
    "# find the top 4 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "f_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4728a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b10bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3c2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22270952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not coming into modeling\n",
    "#train = train.drop(['fips', 'latitude', 'longitude', 'year_built', 'transaction_date', 'parcel_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "# Create the correlation matrix for all exams.\n",
    "\n",
    "zillow_corr = train.corr()\n",
    "zillow_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(zillow_corr, cmap='Purples', annot=True, linewidth=0.5, mask= np.triu(zillow_corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass my correlation matrix to Seaborn's heatmap.\n",
    "\n",
    "kwargs = {'alpha':.9,'linewidth':3, 'linestyle':'-', \n",
    "          'linecolor':'k','rasterized':False, 'edgecolor':'w', \n",
    "          'capstyle':'projecting',}\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(zillow_corr, cmap='Purples', annot=True, mask= np.triu(zillow_corr), **kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd11e7",
   "metadata": {},
   "source": [
    "## Statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9a24f",
   "metadata": {},
   "source": [
    "### Testing Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e694d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to make county a dummy variable so I can use it in this\n",
    "#Make dummy variables from county and rename them to make it easier\n",
    "#train = pd.get_dummies(train, columns=['county'], drop_first=False)\n",
    "train = train.rename(columns = {'county_Los Angeles':'LA', 'county_Orange':'Orange','county_Ventura':'Ventura'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64631f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using all variables for this first\n",
    "X = train[['square_feet','bathrooms','home_age', 'LA']]\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "  \n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088c83c",
   "metadata": {},
   "source": [
    "## Modeling iteration 2 (Features: Bathrooms, Square Feet, Home Age, LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106bddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2_prep(train,validate,test):\n",
    "    '''\n",
    "    This function prepares train, validate, test for model 2 by dropping columns not necessary\n",
    "    or compatible with modeling algorithms.\n",
    "    '''\n",
    "    # drop columns not needed for model 2\n",
    "    keep_cols = ['bathrooms',\n",
    "                 'square_feet',\n",
    "                 'home_age',\n",
    "                 'LA',\n",
    "                 'tax_value',\n",
    "                 ]\n",
    "    \n",
    "    train = train[keep_cols]\n",
    "    validate = validate[keep_cols]\n",
    "    test = test[keep_cols]\n",
    "\n",
    "    # Split data into predicting variables (X) and target variable (y) and reset the index for each dataframe\n",
    "    X_train = train.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_train = train[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "    X_validate = validate.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_validate = validate[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "    X_test = test.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_test = test[['tax_value']].reset_index(drop=True)\n",
    "    \n",
    "    return X_train, X_validate, X_test, y_train, y_validate, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = m.model2_prep(train,validate,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Target Variable\n",
    "plt.hist(y_train)\n",
    "plt.xlabel(\"Tax_Value\")\n",
    "plt.ylabel(\"Count of Tax Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a373e4",
   "metadata": {},
   "source": [
    "### Making predictions using my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f80fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "\n",
    "# 1. compute tax_value_pred_mean\n",
    "\n",
    "tax_value_pred_median = y_train['tax_value'].median()\n",
    "y_train['tax_value_pred_median'] = tax_value_pred_median\n",
    "y_validate['tax_value_pred_median'] = tax_value_pred_median\n",
    "\n",
    "# 4. RMSE of tax_value_pred_median\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_median)**(1/2)\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_median)**(1/2)\n",
    "\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to re-run this without scaled data\n",
    "# plot to visualize actual vs predicted. \n",
    "plt.hist(y_train.tax_value, color='blue', alpha=.5, label=\"Actual Tax Value\")\n",
    "plt.hist(y_train.tax_value_pred_median, bins=1, color='red', alpha=.5, rwidth=100, label=\"Predicted Final Grades - Median\")\n",
    "plt.xlabel(\"Tax Value\")\n",
    "plt.ylabel(\"Count of Homes\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree3 = pf.transform(X_validate)\n",
    "X_test_degree3 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "pf3 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "pf3.fit(X_train_degree3, y_train.tax_value)\n",
    "\n",
    "# predict train\n",
    "y_train['tax_value_pred_pf3'] = pf3.predict(X_train_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_pf3)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['tax_value_pred_pf3'] = pf3.predict(X_validate_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_pf3)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=3\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc0c31",
   "metadata": {},
   "source": [
    "### Plotting Actual vs Predicted values for Polynomial Features (Model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca95f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.tax_value, y_validate.tax_value_pred_median, alpha=.5, color=\"gray\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.tax_value, y_validate.tax_value, alpha=.5, color=\"blue\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.tax_value, y_validate.tax_value_pred_pf3, \n",
    "            alpha=.5, color=\"red\", s=100, label=\"Model: Polynomial Features 3rd Degree\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual Tax Value\")\n",
    "plt.ylabel(\"Predicted Tax Value\")\n",
    "plt.title(\"Predicted values using polynomial features to the third degree\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7e350",
   "metadata": {},
   "source": [
    "### Plotting Errors in my predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.axhline(label=\"No Error\")\n",
    "plt.scatter(y_validate.tax_value, y_validate.tax_value_pred_pf3-y_validate.tax_value, \n",
    "            alpha=.5, color=\"red\", s=100, label=\"Model: Polynomial Features 3rd Degree\")\n",
    "#plt.scatter(y_validate.tax_value, y_validate.tax_value_pred_pf3-y_validate.tax_value, \n",
    "            #alpha=.5, color=\"yellow\", s=100, label=\"Model: TweedieRegressor\")\n",
    "#plt.scatter(y_validate.G3, y_validate.G3_pred_lm2-y_validate.G3, \n",
    "            #alpha=.5, color=\"green\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual Tax Value\")\n",
    "plt.ylabel(\"Residual/Error: Predicted Tax Value - Actual Tax Value\")\n",
    "plt.title(\"Do the size of errors change as the actual value changes?\")\n",
    "#plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "#plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92668466",
   "metadata": {},
   "source": [
    "### Plot to visualize actual vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to visualize actual vs predicted. \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(y_validate.tax_value, color='blue', alpha=.5, label=\"Actual Tax Value\")\n",
    "plt.hist(y_validate.tax_value_pred_pf3, color='red', alpha=.5, label=\"Model: Polynomial Features 3rd Degree\")\n",
    "#plt.hist(y_validate.G3_pred_glm, color='yellow', alpha=.5, label=\"Model: TweedieRegressor\")\n",
    "#plt.hist(y_validate.G3_pred_lm2, color='green', alpha=.5, label=\"Model 2nd degree Polynomial\")\n",
    "plt.xlabel(\"Tax Value\")\n",
    "plt.ylabel(\"Count of Properties\")\n",
    "plt.title(\"Comparing the Distribution of Actual Tax Value to Distributions of Predicted Tax Value for the Top Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceddba66",
   "metadata": {},
   "source": [
    "#### Polynomial Features 3rd degree gave RMSE of 263,877 to in sample and 265,954 to out of sample data, for a difference of 2,077. 4th and 2nd degree were not as good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4e35e",
   "metadata": {},
   "source": [
    "### Model Pause: Let's check these features on different model types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197224c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "# create the model object\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm.fit(X_train, y_train.tax_value)\n",
    "\n",
    "# predict train\n",
    "y_train['tax_value_pred_lm'] = lm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['tax_value_pred_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lm)**(1/2)\n",
    "\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4456b29",
   "metadata": {},
   "source": [
    "#### Linear Regression did not perform as well with RMSE scores of : Training/In-Sample:  273614, Validation/Out-of-Sample:  275409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6687bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso-Lars\n",
    "#create the model object\n",
    "lars = LassoLars(alpha=1)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lars.fit(X_train, y_train.tax_value)\n",
    "\n",
    "# predict train\n",
    "y_train['tax_value_pred_lars'] = lars.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lars)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['tax_value_pred_lars'] = lars.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lars)**(1/2)\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f1c32",
   "metadata": {},
   "source": [
    "#### RMSE for Lasso Lars is similar to Linear Regression: Training/In-Sample:  273614, Validation/Out-of-Sample:  275420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f411037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying Tweedie Regressor\n",
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train, y_train.tax_value)\n",
    "\n",
    "# predict train\n",
    "y_train['tax_value_pred_glm'] = glm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_glm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['tax_value_pred_glm'] = glm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_glm)**(1/2)\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947665ac",
   "metadata": {},
   "source": [
    "#### RMSE for Tweedie (GLS) is not as good as Lasso-Lars with Training/In-Sample:  274707,  Validation/Out-of-Sample:  274456"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440b85d",
   "metadata": {},
   "source": [
    "## Modeling Iteration 3: Features (Bedrooms, Square Feet, Home Age, LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "491a1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3_prep(train,validate,test):\n",
    "    '''\n",
    "    This function prepares train, validate, test for model 3 by dropping columns not necessary\n",
    "    or compatible with modeling algorithms.\n",
    "    '''\n",
    "    # drop columns not needed for model 2\n",
    "    keep_cols = ['bedrooms',\n",
    "                 'square_feet',\n",
    "                 'home_age',\n",
    "                 'LA',\n",
    "                 'tax_value',\n",
    "                 ]\n",
    "    \n",
    "    train = train[keep_cols]\n",
    "    validate = validate[keep_cols]\n",
    "    test = test[keep_cols]\n",
    "\n",
    "    # Split data into predicting variables (X) and target variable (y) and reset the index for each dataframe\n",
    "    X_train = train.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_train = train[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "    X_validate = validate.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_validate = validate[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "    X_test = test.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_test = test[['tax_value']].reset_index(drop=True)\n",
    "    \n",
    "    return X_train, X_validate, X_test, y_train, y_validate, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b26267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = model3_prep(train,validate,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd0de1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Median\n",
      "Train/In-Sample:  334444.03 \n",
      "Validate/Out-of-Sample:  338568.5\n"
     ]
    }
   ],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "\n",
    "# 1. compute tax_value_pred_mean\n",
    "\n",
    "tax_value_pred_median = y_train['tax_value'].median()\n",
    "y_train['tax_value_pred_median'] = tax_value_pred_median\n",
    "y_validate['tax_value_pred_median'] = tax_value_pred_median\n",
    "\n",
    "# 4. RMSE of tax_value_pred_median\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_median)**(1/2)\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_median)**(1/2)\n",
    "\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12f67d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Features\n",
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree3 = pf.transform(X_validate)\n",
    "X_test_degree3 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d09768b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Polynomial Model, degrees=3\n",
      "Training/In-Sample:  263845.5364800431 \n",
      "Validation/Out-of-Sample:  266369.72024936136\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "pf3 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "pf3.fit(X_train_degree3, y_train.tax_value)\n",
    "\n",
    "# predict train\n",
    "y_train['tax_value_pred_pf3'] = pf3.predict(X_train_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_pf3)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['tax_value_pred_pf3'] = pf3.predict(X_validate_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_pf3)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=3\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ce109",
   "metadata": {},
   "source": [
    "#### Model 3 (Bedrooms, Sq Feet, Home Age, LA) performed similarly on train, but with a bigger difference on validate: Training/In-Sample:  263846, Validation/Out-of-Sample:  266370"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f404d92",
   "metadata": {},
   "source": [
    "## Modeling Iteration 4: Features (Bedrooms, Bathrooms, Square Feet, Home Age, LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817d199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4_prep(train,validate,test):\n",
    "    '''\n",
    "    This function prepares train, validate, test for model 3 by dropping columns not necessary\n",
    "    or compatible with modeling algorithms.\n",
    "    '''\n",
    "    # drop columns not needed for model 2\n",
    "    keep_cols = ['bedrooms',\n",
    "                 'bathrooms',\n",
    "                 'square_feet',\n",
    "                 'home_age',\n",
    "                 'LA',\n",
    "                 'tax_value',\n",
    "                 ]\n",
    "    \n",
    "    train = train[keep_cols]\n",
    "    validate = validate[keep_cols]\n",
    "    test = test[keep_cols]\n",
    "\n",
    "    # Split data into predicting variables (X) and target variable (y) and reset the index for each dataframe\n",
    "    X_train = train.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_train = train[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "    X_validate = validate.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_validate = validate[['tax_value']].reset_index(drop=True)\n",
    "\n",
    "    X_test = test.drop(columns='tax_value').reset_index(drop=True)\n",
    "    y_test = test[['tax_value']].reset_index(drop=True)\n",
    "    \n",
    "    return X_train, X_validate, X_test, y_train, y_validate, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99088782",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = model4_prep(train,validate,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7311fcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>home_age</th>\n",
       "      <th>LA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.231577</td>\n",
       "      <td>0.416058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.390737</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  square_feet  home_age  LA\n",
       "0       0.6   0.363636     0.231577  0.416058   1\n",
       "1       0.4   0.454545     0.390737  0.109489   0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509c4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Features\n",
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree3 = pf.transform(X_validate)\n",
    "X_test_degree3 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01814a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Polynomial Model, degrees=3\n",
      "Training/In-Sample:  261446.81598804137 \n",
      "Validation/Out-of-Sample:  263557.7419617677\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "pf3 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "pf3.fit(X_train_degree3, y_train.tax_value)\n",
    "\n",
    "# predict train\n",
    "y_train['tax_value_pred_pf3'] = pf3.predict(X_train_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_pf3)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['tax_value_pred_pf3'] = pf3.predict(X_validate_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_pf3)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=3\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9af2b",
   "metadata": {},
   "source": [
    "### Model 4 (Using both bed and bath) had a lower RMSE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
